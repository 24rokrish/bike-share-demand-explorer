{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ca887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8747ead1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfeatures\u001b[39;00m                      \u001b[38;5;66;03m# your helper module\u001b[39;00m\n\u001b[32m      7\u001b[39m plt.style.use(\u001b[33m\"\u001b[39m\u001b[33mggplot\u001b[39m\u001b[33m\"\u001b[39m)              \u001b[38;5;66;03m# nicer default look\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# --- Load data --------------------------------------------------\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'features'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import features                      # your helper module\n",
    "\n",
    "plt.style.use(\"ggplot\")              # nicer default look\n",
    "\n",
    "# --- Load data --------------------------------------------------\n",
    "DATA  = Path.cwd().parent            # one level up from /notebooks\n",
    "train = pd.read_csv(DATA / \"train.csv\")\n",
    "\n",
    "# --- Feature engineering ---------------------------------------\n",
    "train = features.add_time_features(train)   # adds hour/weekday/month\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])  # ensure datetime dtype\n",
    "\n",
    "train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27c41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_load_features.py\n",
    "DATA = Path.cwd().parent        # one level up from /notebooks\n",
    "train = pd.read_csv(DATA / \"train.csv\")\n",
    "\n",
    "# basic engineered columns\n",
    "train = (\n",
    "    train.pipe(features.add_time_features)\n",
    "         .pipe(features.add_weather_buckets)\n",
    "         # .pipe(features.add_rolling_mean, hours=3)   # optional if you engineered lag\n",
    ")\n",
    "\n",
    "# target and initial feature set\n",
    "TARGET = \"count\"\n",
    "FEATURES = [\"hour\", \"weekday\", \"month\",\n",
    "            \"temp\", \"humidity\", \"windspeed\"]   # start simple\n",
    "\n",
    "X = train[FEATURES]\n",
    "y = train[TARGET]\n",
    "\n",
    "print(f\"Feature matrix: {X.shape}\\nTarget: {y.shape}\")\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4bb32",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e63530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03_train_val_split.py\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"Validation size:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f4efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 04_fit_rf.py\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be981b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 05_eval.py\n",
    "# clip negatives to satisfy log error\n",
    "preds = np.clip(rf.predict(X_val), 0, None)\n",
    "\n",
    "rmsle = mean_squared_log_error(y_val, preds, squared=False)\n",
    "print(f\"Baseline RandomForest RMSLE: {rmsle:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
